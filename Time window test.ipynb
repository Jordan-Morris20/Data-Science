{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import datetime\n",
    "import tensorflow_addons as tfa\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exports():   \n",
    "    # Set CUDA and CUPTI paths  \n",
    "    os.environ['CUDA_HOME'] = '/usr/local/cuda'\n",
    "    os.environ['PATH']= '/usr/local/cuda/bin:$PATH'  \n",
    "    os.environ['CPATH'] = '/usr/local/cuda/include:$CPATH'  \n",
    "    os.environ['LIBRARY_PATH'] = '/usr/local/cuda/lib64:$LIBRARY_PATH'  \n",
    "    os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH'  \n",
    "    os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda/lib64:$LD_LIBRARY_PATH'\n",
    "    os.environ['TF_GPU_THREAD_MODE']='gpu_private'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.exports()>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf15= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/cf15.csv', low_memory=False, header=None)\n",
    "gf25= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/gf25.csv', low_memory=False, header=None)\n",
    "gf34= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/gf34.csv', low_memory=False, header=None)\n",
    "gm01= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/gm01.csv', low_memory=False, header=None)\n",
    "hc10= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/hc10.csv', low_memory=False, header=None)\n",
    "nc46= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/nc46.csv', low_memory=False, header=None)\n",
    "nc74= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/nc74.csv', low_memory=False, header=None)\n",
    "nf11= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/nf11.csv', low_memory=False, header=None)\n",
    "no22= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/no22.csv', low_memory=False, header=None)\n",
    "wc16= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wc16.csv', low_memory=False, header=None)\n",
    "wc41= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wc41.csv', low_memory=False, header=None)\n",
    "wo27= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo27.csv', low_memory=False, header=None)\n",
    "wo34= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo34.csv', low_memory=False, header=None)\n",
    "wo36= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo36.csv', low_memory=False, header=None)\n",
    "wo37= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo37.csv', low_memory=False, header=None)\n",
    "wo40= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo40.csv', low_memory=False, header=None)\n",
    "wo45= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo45.csv', low_memory=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_1 = pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/gm01_EarlyMarch.csv', low_memory=False, header=None)\n",
    "val_2 = pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo36_EarlyMarch.csv', low_memory=False, header=None)\n",
    "val_3 = pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/go22.csv', low_memory=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames =[cf15, gf25,gm01,nc46, nc74,nf11, wc16, wc41,wo27,wo34, wo36, wo37, wo40, wo45]\n",
    "frames_2=[val_1, val_2, val_3]\n",
    "data = pd.concat(frames)\n",
    "val = pd.concat(frames_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snip(data):\n",
    "    #Snip unwanted characters \n",
    "\n",
    "    itime= data.iloc[:,0]\n",
    "    itime=itime.map(lambda x: str(x[6:]))\n",
    "    itime=itime.map(lambda x: float(x))\n",
    "\n",
    "    date=itime\n",
    "    minute=date.map(lambda x: time.gmtime(x+7200)[4])\n",
    "    hour=date.map(lambda x: time.gmtime(x+7200)[3])\n",
    "    day=date.map(lambda x: time.gmtime(x+7200)[2])\n",
    "    month=date.map(lambda x: time.gmtime(x+7200)[1])\n",
    "\n",
    "    interface= data.iloc[:,-14]\n",
    "    interface=interface.map(lambda x: str(x))\n",
    "    interface=interface.map(lambda x: str(x[15:]))\n",
    "    interface=interface.map(lambda x: str(x[:-1]))\n",
    "\n",
    "    dev_id=data.iloc[:,3]\n",
    "    dev_id=dev_id.map(lambda x: str(x))    \n",
    "    dev_id=dev_id.map(lambda x: str(x[7:]))\n",
    "    dev_id=dev_id.map(lambda x: str(x[:-1]))\n",
    "\n",
    "    jitter=data.iloc[:, -13]\n",
    "    jitter=jitter.map(lambda x: str(x))\n",
    "    jitter=jitter.map(lambda x: str(x[8:]))\n",
    "    jitter=jitter.map(lambda x: str(x[:-1]))\n",
    "    jitter=jitter.map(lambda x: float(x))\n",
    "\n",
    "    latency= data.iloc[:,-12]\n",
    "    latency=latency.map(lambda x: str(x))\n",
    "    latency=latency.map(lambda x: str(x[9:]))\n",
    "    latency=latency.map(lambda x: str(x[:-1]))\n",
    "    latency=latency.map(lambda x: float(x))\n",
    "\n",
    "    inband= data.iloc[:,-15]\n",
    "    inband=inband.map(lambda x: str(x))\n",
    "    inband=inband.map(lambda x: str(x[22:]))\n",
    "    inband=inband.map(lambda x: str(x[:-5]))\n",
    "    inband=inband.map(lambda x: float(x))\n",
    "\n",
    "    outband= data.iloc[:, -5]\n",
    "    outband=outband.map(lambda x: str(x))\n",
    "    outband=outband.map(lambda x: x.split('\"')[1])\n",
    "    outband=outband.map(lambda x: str(x[:-4]))\n",
    "    outband=outband.map(lambda x: float(x))\n",
    "\n",
    "    packet=data.iloc[:,-4]\n",
    "    packet=packet.map(lambda x: str(x))\n",
    "    packet=packet.map(lambda x: str(x[12:]))\n",
    "    packet=packet.map(lambda x: str(x[:-2]))\n",
    "    packet=packet.map(lambda x: float(x))\n",
    "\n",
    "    status=data.iloc[:,-2]\n",
    "    status=status.map(lambda x: str(x))\n",
    "    status=status.map(lambda x: str(x[8:]))\n",
    "    status=status.map(lambda x: str(x[:-1]))\n",
    "\n",
    "    status[:] = np.where(status==\"up\", 1,0)\n",
    "    status=status.map(lambda x: float(x))\n",
    "    status=status.rolling(20).mean()\n",
    "    status=status.map(np.floor)\n",
    "\n",
    "    train_init=pd.concat([itime, minute, hour, day, month, interface, dev_id, inband, outband, latency, packet, jitter, status], axis=1)\n",
    "    train_init.columns=['Time','Minute', 'Hour','Day','Month', 'Interface', 'Dev_id', 'Inband', 'Outband', 'Latency', 'Packet', 'Jitter', 'Status']\n",
    "\n",
    "    #Dedupp based on interfaces\n",
    "    train=train_init[train_init.Interface != 'NI2A-WWW1']\n",
    "    train=train[train.Interface != 'NI2B-WWW1']\n",
    "    train=train[train.Interface != 'NI2A-WWW2']\n",
    "    train=train[train.Interface != 'NI2B-WWW2']\n",
    "    train=train[train.Interface != 'NI2A-WWW3']    \n",
    "    train=train[train.Interface != 'NI2B-WWW3']\n",
    "    train=train[train.Interface != 'NI2A-MPLS']\n",
    "    train['Interface']= train['Interface'].astype('category')\n",
    "    train['Interface']=train['Interface'].cat.codes\n",
    "\n",
    "    #Remove unwanted columns\n",
    "    train_label=train.filter(['Status'])\n",
    "    train=train.drop(['Status','Inband', 'Outband'], axis=1)\n",
    "    train= train.sort_values(by=['Dev_id', 'Time'])\n",
    "    train=train.reset_index(drop=True)\n",
    "    train=train.drop(['Dev_id'], axis=1)\n",
    "\n",
    "    return train, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,train_label=snip(data)\n",
    "train=train.iloc[:-700, :]\n",
    "train=train.to_numpy()\n",
    "train_label=train_label.iloc[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test,test_label=snip(val)\n",
    "test=test.iloc[:-700, :]\n",
    "test=test.to_numpy()\n",
    "test_label=test_label.iloc[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, train_label = preproccess(data)\n",
    "mean=train.mean(axis=0)\n",
    "train-=mean\n",
    "std = train.std(axis=0)\n",
    "train/=std\n",
    "#test, test_label = preproccess(val)\n",
    "test-=mean\n",
    "test/=std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train, train_label))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 15:31:54.880659: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-09 15:31:54.880684: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-09 15:31:54.901321: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1630] Profiler found 1 GPUs\n",
      "2022-03-09 15:31:54.901848: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory\n",
      "2022-03-09 15:31:54.904855: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-03-09 15:31:54.904979: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu',kernel_regularizer='l1_l2'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(128, activation='relu',kernel_regularizer='l1_l2'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "    model.compile(optimizer='adam',\n",
    "            loss='BinaryCrossentropy',\n",
    "            metrics=tfa.metrics.F1Score(num_classes=1, average='micro'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 15:31:54.973085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 15:31:54.978377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-09 15:31:54.978702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-09 15:31:54.979198: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-09 15:31:54.979458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-09 15:31:54.979799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-09 15:31:54.980070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-09 15:31:55.332223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-09 15:31:55.332544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-09 15:31:55.332824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-09 15:31:55.333085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6699 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 484/5394 [=>............................] - ETA: 14s - loss: 2.6647 - f1_score: 0.7745"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 15:31:58.262431: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-09 15:31:58.262459: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 511/5394 [=>............................] - ETA: 16s - loss: 2.5476 - f1_score: 0.7746"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 15:31:58.566804: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-03-09 15:31:58.567115: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n",
      "2022-03-09 15:31:58.613641: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 4827 callback api events and 4791 activity events. \n",
      "2022-03-09 15:31:58.685335: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 520/5394 [=>............................] - ETA: 20s - loss: 2.5111 - f1_score: 0.7745"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 15:31:58.776752: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/20220309-153154/plugins/profile/2022_03_09_15_31_58\n",
      "\n",
      "2022-03-09 15:31:58.840573: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/20220309-153154/plugins/profile/2022_03_09_15_31_58/jordan-desktop.trace.json.gz\n",
      "2022-03-09 15:31:58.918436: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/20220309-153154/plugins/profile/2022_03_09_15_31_58\n",
      "\n",
      "2022-03-09 15:31:58.923891: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/20220309-153154/plugins/profile/2022_03_09_15_31_58/jordan-desktop.memory_profile.json.gz\n",
      "2022-03-09 15:31:58.925362: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/20220309-153154/plugins/profile/2022_03_09_15_31_58\n",
      "Dumped tool data for xplane.pb to logs/20220309-153154/plugins/profile/2022_03_09_15_31_58/jordan-desktop.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/20220309-153154/plugins/profile/2022_03_09_15_31_58/jordan-desktop.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/20220309-153154/plugins/profile/2022_03_09_15_31_58/jordan-desktop.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/20220309-153154/plugins/profile/2022_03_09_15_31_58/jordan-desktop.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/20220309-153154/plugins/profile/2022_03_09_15_31_58/jordan-desktop.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5394/5394 [==============================] - 17s 3ms/step - loss: 0.5757 - f1_score: 0.7753\n",
      "Epoch 2/5\n",
      "5394/5394 [==============================] - 15s 3ms/step - loss: 0.3462 - f1_score: 0.7753\n",
      "Epoch 3/5\n",
      "5394/5394 [==============================] - 14s 3ms/step - loss: 0.3408 - f1_score: 0.7753\n",
      "Epoch 4/5\n",
      "5394/5394 [==============================] - 14s 3ms/step - loss: 0.3408 - f1_score: 0.7753\n",
      "Epoch 5/5\n",
      "5394/5394 [==============================] - 14s 3ms/step - loss: 0.3428 - f1_score: 0.7753\n"
     ]
    }
   ],
   "source": [
    "model = get_model()       \n",
    "history = model.fit(train, train_label, epochs=5, batch_size=128,  callbacks = [tboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 7541), started 0:32:20 ago. (Use '!kill 7541' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1d98fcd64a81cebe\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1d98fcd64a81cebe\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2910/2910 - 4s - loss: 0.2594 - f1_score: 0.9714 - 4s/epoch - 1ms/step\n",
      "\n",
      "Test Accuracy: 0.9713641405105591\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc =model.evaluate(test, test_label, verbose=2)\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1:31 after loading datasets"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
