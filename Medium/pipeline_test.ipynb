{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-01 16:10:13.397950: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-01 16:10:13.397978: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf15= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/cf15.csv', low_memory=False, header=None)\n",
    "gf25= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/gf25.csv', low_memory=False, header=None)\n",
    "gm01= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/gm01.csv', low_memory=False, header=None)\n",
    "nc46= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/nc46.csv', low_memory=False, header=None)\n",
    "nc74_jan= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/nc74_jan.csv', low_memory=False, header=None)\n",
    "nf11= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/nf11.csv', low_memory=False, header=None)\n",
    "wc16= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wc16.csv', low_memory=False, header=None)\n",
    "wc41= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wc41.csv', low_memory=False, header=None)\n",
    "wo36= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo36.csv', low_memory=False, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_1 = pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/go22.csv', low_memory=False, header=None)\n",
    "val_2 = pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/kf15.csv', low_memory=False, header=None)\n",
    "val_3 = pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/nf28.csv', low_memory=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames =[cf15, nc46, nc74_jan, nf11, wc16, wc41, wo36]\n",
    "frames_2=[val_1, val_2]\n",
    "data = pd.concat(frames)\n",
    "val = pd.concat(frames_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snip(data):\n",
    "    time= data.iloc[:,0]\n",
    "    time=time.map(lambda x: str(x[6:]))\n",
    "    time=time.map(lambda x: float(x))\n",
    "\n",
    "    interface= data.iloc[:,-14]\n",
    "    interface=interface.map(lambda x: str(x[15:]))\n",
    "    interface=interface.map(lambda x: str(x[:-1]))\n",
    "\n",
    "    jitter=data.iloc[:, -13]\n",
    "    jitter=jitter.map(lambda x: str(x))\n",
    "    jitter=jitter.map(lambda x: str(x[8:]))\n",
    "    jitter=jitter.map(lambda x: str(x[:-1]))\n",
    "    jitter=jitter.map(lambda x: float(x))\n",
    "\n",
    "    latency= data.iloc[:,-12]\n",
    "    latency=latency.map(lambda x: str(x))\n",
    "    latency=latency.map(lambda x: str(x[9:]))\n",
    "    latency=latency.map(lambda x: str(x[:-1]))\n",
    "    latency=latency.map(lambda x: float(x))\n",
    "\n",
    "    inband= data.iloc[:,-15]\n",
    "    inband=inband.map(lambda x: str(x))\n",
    "    inband=inband.map(lambda x: str(x[22:]))\n",
    "    inband=inband.map(lambda x: str(x[:-5]))\n",
    "    inband=inband.map(lambda x: float(x))\n",
    "\n",
    "    outband= data.iloc[:, -5]\n",
    "    outband=outband.map(lambda x: str(x))\n",
    "    outband=outband.map(lambda x: x.split('\"')[1])\n",
    "    outband=outband.map(lambda x: str(x[:-4]))\n",
    "    outband=outband.map(lambda x: float(x))\n",
    "\n",
    "    packet=data.iloc[:,-4]\n",
    "    packet=packet.map(lambda x: str(x))\n",
    "    packet=packet.map(lambda x: str(x[12:]))\n",
    "    packet=packet.map(lambda x: str(x[:-2]))\n",
    "    packet=packet.map(lambda x: float(x))\n",
    "\n",
    "    train=pd.concat([time, inband, outband, latency, packet, jitter], axis=1)\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(data):\n",
    "    status=data.iloc[:,-2]\n",
    "    status=status.map(lambda x: str(x))\n",
    "    status=status.map(lambda x: str(x[8:]))\n",
    "    status=status.map(lambda x: str(x[:-1]))\n",
    "\n",
    "    status[:] = np.where(status==\"up\", 1,0)\n",
    "    status=status.map(lambda x: float(x))\n",
    "    status=status.rolling(20).mean()\n",
    "    status=status.map(np.floor)\n",
    "\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproccess(data):\n",
    "    train=snip(data)\n",
    "    train=train.iloc[:-700, :]\n",
    "    train=train.to_numpy()\n",
    "    label=labels(data)\n",
    "    label=label.iloc[700:]\n",
    "    return train, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, label = preproccess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=train.mean(axis=0)\n",
    "train-=mean\n",
    "std = train.std(axis=0)\n",
    "train/=std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, test_label = preproccess(val)\n",
    "test-=mean\n",
    "test/=std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf = {\n",
    "    'time': train[:,0],\n",
    "    'inband':train[:,1],\n",
    "    'outband':train[:,2],\n",
    "    'latency':train[:,3],\n",
    "    'packet':train[:,4],\n",
    "    'jitter': train[:,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = tf.train.Example(features=tf.train.Features(feature={\n",
    "    'time': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=data_tf['time'])),\n",
    "    'inband': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=data_tf['inband'])),\n",
    "    'outband': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=data_tf['outband'])),\n",
    "    'latency': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=data_tf['latency'])),\n",
    "    'packet': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=data_tf['packet'])),\n",
    "    'jitter': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=data_tf['jitter'])),\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess= tf.InteractiveSession()\n",
    "\n",
    "reader = tf.TFRecordReader()\n",
    "filename_queue = tf.train.string_input_producer(['processed_train'])\n",
    "\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "read_features = {\n",
    "    'time':tf.VarLenFeature(dtype=tf.float64),\n",
    "    'inband':tf.VarLenFeature(dtype=tf.float64),\n",
    "    'outband':tf.VarLenFeature(dtype=tf.float64),\n",
    "    'latency':tf.VarLenFeature(dtype=tf.float64),\n",
    "    'packet':tf.VarLenFeature(dtype=tf.float64),\n",
    "    'jitter':tf.VarLenFeature(dtype=tf.float64),\n",
    "}\n",
    "\n",
    "read_data = tf.parse_single_example(serialized=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(10, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(10, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(10, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "    model.compile(optimizer='adam',\n",
    "            loss='BinaryCrossentropy',\n",
    "            metrics=['accuracy'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()       \n",
    "history = model.fit(train, label, epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc =model.evaluate(test, test_label, verbose=2)\n",
    "print('\\nTest Accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
