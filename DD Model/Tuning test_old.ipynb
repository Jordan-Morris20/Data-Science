{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 10:35:56.896414: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-12 10:35:56.896436: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import datetime\n",
    "import tensorflow_addons as tfa\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exports():   \n",
    "    # Set CUDA and CUPTI paths  \n",
    "    os.environ['CUDA_HOME'] = '/usr/local/cuda'\n",
    "    os.environ['PATH']= '/usr/local/cuda/bin:$PATH'  \n",
    "    os.environ['CPATH'] = '/usr/local/cuda/include:$CPATH'  \n",
    "    os.environ['LIBRARY_PATH'] = '/usr/local/cuda/lib64:$LIBRARY_PATH'  \n",
    "    os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH'  \n",
    "    os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda/lib64:$LD_LIBRARY_PATH'\n",
    "    os.environ['TF_GPU_THREAD_MODE']='gpu_private'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.exports()>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf15= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/cf15.csv', low_memory=False, header=None)\n",
    "gf25= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/gf25.csv', low_memory=False, header=None)\n",
    "gf34= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/gf34.csv', low_memory=False, header=None)\n",
    "gm01= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/gm01.csv', low_memory=False, header=None)\n",
    "hc10= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/hc10.csv', low_memory=False, header=None)\n",
    "nc46= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/nc46.csv', low_memory=False, header=None)\n",
    "nc74= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/nc74.csv', low_memory=False, header=None)\n",
    "nf11= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/nf11.csv', low_memory=False, header=None)\n",
    "no22= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/no22.csv', low_memory=False, header=None)\n",
    "wc16= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wc16.csv', low_memory=False, header=None)\n",
    "wc41= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wc41.csv', low_memory=False, header=None)\n",
    "wo27= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo27.csv', low_memory=False, header=None)\n",
    "wo34= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo34.csv', low_memory=False, header=None)\n",
    "wo36= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo36.csv', low_memory=False, header=None)\n",
    "wo37= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo37.csv', low_memory=False, header=None)\n",
    "wo40= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo40.csv', low_memory=False, header=None)\n",
    "wo45= pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo45.csv', low_memory=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_1 = pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/gm01_EarlyMarch.csv', low_memory=False, header=None)\n",
    "val_2 = pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/wo36_EarlyMarch.csv', low_memory=False, header=None)\n",
    "val_3 = pd.read_csv('/home/jordan/Documents/DataSets/DimensionData/go22.csv', low_memory=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames =[cf15, gf25,gm01,nc46, nc74,nf11, wc16, wc41,wo27,wo34, wo36, wo37, wo40, wo45]\n",
    "frames_2=[val_1, val_2, val_3]\n",
    "data = pd.concat(frames)\n",
    "val = pd.concat(frames_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snip(data):\n",
    "    #Snip unwanted characters \n",
    "\n",
    "    itime= data.iloc[:,0]\n",
    "    itime=itime.map(lambda x: str(x[6:]))\n",
    "    itime=itime.map(lambda x: float(x))\n",
    "\n",
    "    date=itime\n",
    "    minute=date.map(lambda x: time.gmtime(x+7200)[4])\n",
    "    hour=date.map(lambda x: time.gmtime(x+7200)[3])\n",
    "    day=date.map(lambda x: time.gmtime(x+7200)[2])\n",
    "    month=date.map(lambda x: time.gmtime(x+7200)[1])\n",
    "\n",
    "    interface= data.iloc[:,-14]\n",
    "    interface=interface.map(lambda x: str(x))\n",
    "    interface=interface.map(lambda x: str(x[15:]))\n",
    "    interface=interface.map(lambda x: str(x[:-1]))\n",
    "\n",
    "    dev_id=data.iloc[:,3]\n",
    "    dev_id=dev_id.map(lambda x: str(x))    \n",
    "    dev_id=dev_id.map(lambda x: str(x[7:]))\n",
    "    dev_id=dev_id.map(lambda x: str(x[:-1]))\n",
    "\n",
    "    jitter=data.iloc[:, -13]\n",
    "    jitter=jitter.map(lambda x: str(x))\n",
    "    jitter=jitter.map(lambda x: str(x[8:]))\n",
    "    jitter=jitter.map(lambda x: str(x[:-1]))\n",
    "    jitter=jitter.map(lambda x: float(x))\n",
    "\n",
    "    latency= data.iloc[:,-12]\n",
    "    latency=latency.map(lambda x: str(x))\n",
    "    latency=latency.map(lambda x: str(x[9:]))\n",
    "    latency=latency.map(lambda x: str(x[:-1]))\n",
    "    latency=latency.map(lambda x: float(x))\n",
    "\n",
    "    inband= data.iloc[:,-15]\n",
    "    inband=inband.map(lambda x: str(x))\n",
    "    inband=inband.map(lambda x: str(x[22:]))\n",
    "    inband=inband.map(lambda x: str(x[:-5]))\n",
    "    inband=inband.map(lambda x: float(x))\n",
    "\n",
    "    outband= data.iloc[:, -5]\n",
    "    outband=outband.map(lambda x: str(x))\n",
    "    outband=outband.map(lambda x: x.split('\"')[1])\n",
    "    outband=outband.map(lambda x: str(x[:-4]))\n",
    "    outband=outband.map(lambda x: float(x))\n",
    "\n",
    "    packet=data.iloc[:,-4]\n",
    "    packet=packet.map(lambda x: str(x))\n",
    "    packet=packet.map(lambda x: str(x[12:]))\n",
    "    packet=packet.map(lambda x: str(x[:-2]))\n",
    "    packet=packet.map(lambda x: float(x))\n",
    "\n",
    "    status=data.iloc[:,-2]\n",
    "    status=status.map(lambda x: str(x))\n",
    "    status=status.map(lambda x: str(x[8:]))\n",
    "    status=status.map(lambda x: str(x[:-1]))\n",
    "\n",
    "    status[:] = np.where(status==\"up\", 1,0)\n",
    "    status=status.map(lambda x: float(x))\n",
    "    status=status.rolling(10).mean()\n",
    "    status=status.map(np.floor)\n",
    "\n",
    "    train_init=pd.concat([itime, minute, hour, day, month, interface, dev_id, inband, outband, latency, packet, jitter, status], axis=1)\n",
    "    train_init.columns=['Time','Minute', 'Hour','Day','Month', 'Interface', 'Dev_id', 'Inband', 'Outband', 'Latency', 'Packet', 'Jitter', 'Status']\n",
    "\n",
    "    #Dedupp based on interfaces\n",
    "    train=train_init[train_init.Interface != 'NI2A-WWW1']\n",
    "    train=train[train.Interface != 'NI2B-WWW1']\n",
    "    train=train[train.Interface != 'NI2A-WWW2']\n",
    "    train=train[train.Interface != 'NI2B-WWW2']\n",
    "    train=train[train.Interface != 'NI2A-WWW3']    \n",
    "    train=train[train.Interface != 'NI2B-WWW3']\n",
    "    train=train[train.Interface != 'NI2A-MPLS']\n",
    "    train['Interface']= train['Interface'].astype('category')\n",
    "    train['Interface']=train['Interface'].cat.codes\n",
    "\n",
    "    #Remove unwanted columns\n",
    "    train_label=train.filter(['Status'])\n",
    "    train=train.drop(['Status','Inband', 'Outband'], axis=1)\n",
    "    train= train.sort_values(by=['Dev_id', 'Time'])\n",
    "    train=train.reset_index(drop=True)\n",
    "    train=train.drop(['Dev_id'], axis=1)\n",
    "\n",
    "    return train, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,train_label=snip(data)\n",
    "train=train.iloc[:-700, :]\n",
    "train=train.to_numpy()\n",
    "train_label=train_label.iloc[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test,test_label=snip(val)\n",
    "test=test.iloc[:-700, :]\n",
    "test=test.to_numpy()\n",
    "test_label=test_label.iloc[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, train_label = preproccess(data)\n",
    "mean=train.mean(axis=0)\n",
    "train-=mean\n",
    "std = train.std(axis=0)\n",
    "train/=std\n",
    "#test, test_label = preproccess(val)\n",
    "test-=mean\n",
    "test/=std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 10:36:44.103407: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-03-12 10:36:44.103457: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-03-12 10:36:44.106421: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-12 10:36:44.106798: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(hp):\n",
    "    model=tf.keras.Sequential()\n",
    "    #Tune number of layers\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 4)):\n",
    "        model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=16, max_value=320, step=32),\n",
    "                activation=hp.Choice('activation',['elu','relu','tanh'])\n",
    "            )\n",
    "        )\n",
    "        if hp.Boolean(\"dropout\"):\n",
    "            model.add(tf.keras.layers.Dropout(rate=hp.Choice('rate',[0.3,0.4,0.45,0.5])))\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='BinaryCrossentropy',\n",
    "                metrics=tfa.metrics.F1Score(num_classes=1, average='micro'))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project /home/jordan/Documents/DataSets/Data-Science/test5/Tuning_test/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from /home/jordan/Documents/DataSets/Data-Science/test5/Tuning_test/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 10:36:44.567708: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-12 10:36:44.567832: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pop-os): /proc/driver/nvidia/version does not exist\n",
      "2022-03-12 10:36:44.570063: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(get_model,\n",
    "                     objective=kt.Objective(\"val_f1_score\", direction=\"max\"),\n",
    "                     max_epochs=15,\n",
    "                     factor=2,\n",
    "                     hyperband_iterations=3,\n",
    "                     directory='/home/jordan/Documents/DataSets/Data-Science/test6',\n",
    "                     project_name='Tuning_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 185 Complete [00h 02m 28s]\n",
      "val_f1_score: 0.0245242640376091\n",
      "\n",
      "Best val_f1_score So Far: 0.5479933023452759\n",
      "Total elapsed time: 00h 06m 30s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train, train_label, epochs=50, validation_split=0.2,\n",
    "callbacks= [callback])\n",
    "\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17259/17259 [==============================] - 25s 1ms/step - loss: 7.5989 - f1_score: 0.0399 - val_loss: 10.8469 - val_f1_score: 0.0404\n",
      "Epoch 2/50\n",
      "17259/17259 [==============================] - 24s 1ms/step - loss: 7.0020 - f1_score: 0.0381 - val_loss: 8.7535 - val_f1_score: 0.4136\n",
      "Epoch 3/50\n",
      "17259/17259 [==============================] - 24s 1ms/step - loss: 6.8833 - f1_score: 0.0382 - val_loss: 8.3107 - val_f1_score: 0.4248\n",
      "Epoch 4/50\n",
      "17259/17259 [==============================] - 24s 1ms/step - loss: 6.7977 - f1_score: 0.0383 - val_loss: 6.9275 - val_f1_score: 0.2368\n",
      "Epoch 5/50\n",
      "17259/17259 [==============================] - 24s 1ms/step - loss: 6.7519 - f1_score: 0.0388 - val_loss: 6.7466 - val_f1_score: 0.2476\n",
      "Epoch 6/50\n",
      "17259/17259 [==============================] - 24s 1ms/step - loss: 6.7267 - f1_score: 0.0388 - val_loss: 7.1302 - val_f1_score: 0.3016\n",
      "Epoch 7/50\n",
      "17259/17259 [==============================] - 24s 1ms/step - loss: 6.7127 - f1_score: 0.0388 - val_loss: 6.6176 - val_f1_score: 0.2064\n",
      "Epoch 8/50\n",
      "17259/17259 [==============================] - 24s 1ms/step - loss: 6.6965 - f1_score: 0.0389 - val_loss: 6.7098 - val_f1_score: 0.2480\n",
      "Epoch 9/50\n",
      "17259/17259 [==============================] - 24s 1ms/step - loss: 6.6813 - f1_score: 0.0390 - val_loss: 6.5504 - val_f1_score: 0.2226\n",
      "Epoch 10/50\n",
      "17259/17259 [==============================] - 24s 1ms/step - loss: 6.6838 - f1_score: 0.0390 - val_loss: 6.2257 - val_f1_score: 0.1784\n",
      "Epoch 11/50\n",
      "17259/17259 [==============================] - 24s 1ms/step - loss: 6.6794 - f1_score: 0.0391 - val_loss: 6.4762 - val_f1_score: 0.2058\n",
      "Epoch 12/50\n",
      "17259/17259 [==============================] - 24s 1ms/step - loss: 6.6721 - f1_score: 0.0390 - val_loss: 6.7033 - val_f1_score: 0.2477\n",
      "Epoch 13/50\n",
      "17259/17259 [==============================] - 24s 1ms/step - loss: 6.6623 - f1_score: 0.0390 - val_loss: 6.5958 - val_f1_score: 0.2210\n",
      "Epoch 14/50\n",
      "17259/17259 [==============================] - 24s 1ms/step - loss: 6.6644 - f1_score: 0.0389 - val_loss: 6.6644 - val_f1_score: 0.2432\n",
      "Epoch 15/50\n",
      "17259/17259 [==============================] - 25s 1ms/step - loss: 6.6650 - f1_score: 0.0390 - val_loss: 6.6764 - val_f1_score: 0.2378\n",
      "Epoch 16/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6665 - f1_score: 0.0390 - val_loss: 6.5320 - val_f1_score: 0.2237\n",
      "Epoch 17/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6736 - f1_score: 0.0390 - val_loss: 6.5184 - val_f1_score: 0.2211\n",
      "Epoch 18/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6656 - f1_score: 0.0389 - val_loss: 6.5376 - val_f1_score: 0.2223\n",
      "Epoch 19/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6594 - f1_score: 0.0390 - val_loss: 6.6818 - val_f1_score: 0.2402\n",
      "Epoch 20/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6570 - f1_score: 0.0391 - val_loss: 6.6450 - val_f1_score: 0.2299\n",
      "Epoch 21/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6503 - f1_score: 0.0391 - val_loss: 6.4880 - val_f1_score: 0.2129\n",
      "Epoch 22/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6524 - f1_score: 0.0391 - val_loss: 6.7665 - val_f1_score: 0.2619\n",
      "Epoch 23/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6634 - f1_score: 0.0391 - val_loss: 6.9568 - val_f1_score: 0.2875\n",
      "Epoch 24/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6505 - f1_score: 0.0391 - val_loss: 6.6770 - val_f1_score: 0.2390\n",
      "Epoch 25/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6479 - f1_score: 0.0391 - val_loss: 6.7228 - val_f1_score: 0.2505\n",
      "Epoch 26/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6419 - f1_score: 0.0391 - val_loss: 6.6138 - val_f1_score: 0.2352\n",
      "Epoch 27/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6467 - f1_score: 0.0390 - val_loss: 6.7328 - val_f1_score: 0.2564\n",
      "Epoch 28/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6398 - f1_score: 0.0391 - val_loss: 6.7010 - val_f1_score: 0.2474\n",
      "Epoch 29/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6511 - f1_score: 0.0389 - val_loss: 6.5172 - val_f1_score: 0.2188\n",
      "Epoch 30/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6476 - f1_score: 0.0391 - val_loss: 6.7434 - val_f1_score: 0.2574\n",
      "Epoch 31/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6448 - f1_score: 0.0391 - val_loss: 6.6605 - val_f1_score: 0.2414\n",
      "Epoch 32/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6729 - f1_score: 0.0392 - val_loss: 6.6454 - val_f1_score: 0.2416\n",
      "Epoch 33/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6498 - f1_score: 0.0391 - val_loss: 6.7347 - val_f1_score: 0.2554\n",
      "Epoch 34/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6599 - f1_score: 0.0391 - val_loss: 6.7310 - val_f1_score: 0.2537\n",
      "Epoch 35/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6518 - f1_score: 0.0391 - val_loss: 6.6945 - val_f1_score: 0.2493\n",
      "Epoch 36/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6388 - f1_score: 0.0391 - val_loss: 6.7400 - val_f1_score: 0.2527\n",
      "Epoch 37/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6396 - f1_score: 0.0391 - val_loss: 6.7121 - val_f1_score: 0.2503\n",
      "Epoch 38/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6393 - f1_score: 0.0391 - val_loss: 6.7347 - val_f1_score: 0.2574\n",
      "Epoch 39/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6399 - f1_score: 0.0390 - val_loss: 6.7658 - val_f1_score: 0.2621\n",
      "Epoch 40/50\n",
      "17259/17259 [==============================] - 21s 1ms/step - loss: 6.6307 - f1_score: 0.0391 - val_loss: 6.5356 - val_f1_score: 0.2225\n",
      "Epoch 41/50\n",
      "17259/17259 [==============================] - 25s 1ms/step - loss: 6.6237 - f1_score: 0.0389 - val_loss: 6.7573 - val_f1_score: 0.2606\n",
      "Epoch 42/50\n",
      "17259/17259 [==============================] - 42s 2ms/step - loss: 6.6052 - f1_score: 0.0390 - val_loss: 7.0094 - val_f1_score: 0.2936\n",
      "Epoch 43/50\n",
      "17259/17259 [==============================] - 37s 2ms/step - loss: 6.5968 - f1_score: 0.0390 - val_loss: 6.7194 - val_f1_score: 0.2556\n",
      "Epoch 44/50\n",
      "17259/17259 [==============================] - 43s 2ms/step - loss: 6.5930 - f1_score: 0.0389 - val_loss: 6.7511 - val_f1_score: 0.2597\n",
      "Epoch 45/50\n",
      "17259/17259 [==============================] - 45s 3ms/step - loss: 6.5726 - f1_score: 0.0390 - val_loss: 6.7218 - val_f1_score: 0.2537\n",
      "Epoch 46/50\n",
      "17259/17259 [==============================] - 41s 2ms/step - loss: 6.5895 - f1_score: 0.0391 - val_loss: 6.7554 - val_f1_score: 0.2602\n",
      "Epoch 47/50\n",
      "17259/17259 [==============================] - 37s 2ms/step - loss: 6.5819 - f1_score: 0.0390 - val_loss: 6.5753 - val_f1_score: 0.2244\n",
      "Epoch 48/50\n",
      "17259/17259 [==============================] - 44s 3ms/step - loss: 6.5831 - f1_score: 0.0390 - val_loss: 6.3030 - val_f1_score: 0.1870\n",
      "Epoch 49/50\n",
      "17259/17259 [==============================] - 44s 3ms/step - loss: 6.5725 - f1_score: 0.0391 - val_loss: 6.6994 - val_f1_score: 0.2486\n",
      "Epoch 50/50\n",
      "17259/17259 [==============================] - 46s 3ms/step - loss: 6.5863 - f1_score: 0.0390 - val_loss: 6.7805 - val_f1_score: 0.2642\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(train, train_label, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 3\n"
     ]
    }
   ],
   "source": [
    "val_acc_per_epoch = history.history[\"val_f1_score\"]\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "17259/17259 [==============================] - 40s 2ms/step - loss: 7.5869 - f1_score: 0.0402 - val_loss: 6.8766 - val_f1_score: 0.0404\n",
      "Epoch 2/3\n",
      "17259/17259 [==============================] - 42s 2ms/step - loss: 7.0902 - f1_score: 0.0395 - val_loss: 6.9802 - val_f1_score: 0.4412\n",
      "Epoch 3/3\n",
      "17259/17259 [==============================] - 42s 2ms/step - loss: 6.8272 - f1_score: 0.0383 - val_loss: 8.4847 - val_f1_score: 0.5281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7d3f9cb970>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "#Retrain the model\n",
    "hypermodel.fit(train, train_label, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2910/2910 [==============================] - 4s 1ms/step - loss: 0.7950 - f1_score: 0.0408\n",
      "[test loss, test accuracy]: [0.7949805855751038, 0.040769148617982864]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(test, test_label)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel.save('tuned_model5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 48)                480       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 48)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                784       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 48)                816       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 48)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,080\n",
      "Trainable params: 2,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hypermodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
